import asyncio
import json
import logging
import random
from typing import Optional, Dict, Any, Tuple

from fastapi import APIRouter, Request, HTTPException

from .base_proxy import (
  base_proxy_request,
  KeyManager,
  ProxyError
)
from .... import crud
from ....core.config import settings
from ....core.security import db_dependency

logger = logging.getLogger(__name__)

router = APIRouter(prefix=settings.GEMINI_PURE_PROXY_PREFIX, tags=["Gemini Pure Proxy"])

# é…ç½®ç¼“å­˜ï¼Œé¿å…é‡å¤æŸ¥è¯¢æ•°æ®åº“
_config_cache: Dict[str, Any] = {}
_cache_timestamp = 0
CACHE_TTL = 300  # 5åˆ†é’Ÿç¼“å­˜è¿‡æœŸæ—¶é—´

# é‡è¯•é…ç½®
INITIAL_RETRY_DELAY = 0.1  # åˆå§‹é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
MAX_RETRY_DELAY = 1.0  # æœ€å¤§é‡è¯•å»¶è¿Ÿï¼ˆç§’ï¼‰
RETRY_BACKOFF_FACTOR = 1.5  # æŒ‡æ•°é€€é¿å› å­


def _get_cached_configs(db: db_dependency) -> Tuple[Optional[str], Optional[str], Optional[int]]:
  """è·å–ç¼“å­˜çš„é…ç½®ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢"""
  global _config_cache, _cache_timestamp
  import time

  current_time = time.time()

  # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
  if current_time - _cache_timestamp > CACHE_TTL:
    try:
      # æ‰¹é‡æŸ¥è¯¢é…ç½®
      target_config = crud.config.get_config_by_key(db, "target_api_url")
      api_token_config = crud.config.get_config_by_key(db, "api_token")
      retry_count_config = crud.config.get_config_by_key(db, "proxy_retry_max_count")

      _config_cache = {
        "target_api_url": target_config.value if target_config else None,
        "api_token": api_token_config.value if api_token_config else None,
        "proxy_retry_max_count": int(retry_count_config.value) if retry_count_config and retry_count_config.value else 3
      }
      _cache_timestamp = current_time
      logger.debug("Configuration cache refreshed")
    except Exception as e:
      logger.error(f"Failed to refresh configuration cache: {e}")
      # å¦‚æœç¼“å­˜åˆ·æ–°å¤±è´¥ï¼Œä¿æŒåŸæœ‰ç¼“å­˜æˆ–è¿”å›é»˜è®¤å€¼
      if not _config_cache:
        return None, None, 3

  return (
    _config_cache.get("target_api_url"),
    _config_cache.get("api_token"),
    _config_cache.get("proxy_retry_max_count", 3)
  )


def _extract_stream_parameter(body: bytes) -> Tuple[bool, Optional[Dict[str, Any]]]:
  """å®‰å…¨åœ°è§£æè¯·æ±‚ä½“ä¸­çš„streamå‚æ•°"""
  if not body:
    return False, None

  try:
    request_data = json.loads(body)
    if not isinstance(request_data, dict):
      logger.warning("Request body is not a JSON object")
      return False, request_data

    stream_value = request_data.get("stream")
    if stream_value is None:
      return False, request_data

    if isinstance(stream_value, bool):
      logger.debug(f"Stream parameter found in request body: {stream_value}")
      return stream_value, request_data
    else:
      logger.warning(f"Invalid stream parameter type: {type(stream_value)}, expected bool")
      return False, request_data

  except json.JSONDecodeError as e:
    logger.warning(f"Failed to decode JSON request body: {e}")
    return False, None
  except Exception as e:
    logger.error(f"Unexpected error parsing request body: {e}", exc_info=True)
    return False, None


def _is_retryable_error(exception: Exception) -> bool:
  """åˆ¤æ–­å¼‚å¸¸æ˜¯å¦å¯ä»¥é‡è¯•"""
  if isinstance(exception, HTTPException):
    # 4xxå’Œ5xxé”™è¯¯éƒ½å¯ä»¥é‡è¯•ï¼ˆé™¤äº†400å‚æ•°é”™è¯¯ï¼Œå› ä¸ºæ¢keyæ— æ³•è§£å†³å‚æ•°é—®é¢˜ï¼‰
    return exception.status_code >= 400 and exception.status_code != 400

  if isinstance(exception, ProxyError):
    # åŸºäºProxyErrorçš„çŠ¶æ€ç åˆ¤æ–­ï¼Œ4xxå’Œ5xxéƒ½å¯ä»¥é‡è¯•ï¼ˆé™¤äº†400ï¼‰
    return exception.status_code >= 400 and exception.status_code != 400

  # ç½‘ç»œç›¸å…³é”™è¯¯é€šå¸¸å¯ä»¥é‡è¯•
  error_types = (
    ConnectionError,
    TimeoutError,
    OSError,  # åŒ…æ‹¬ç½‘ç»œç›¸å…³çš„OSError
  )

  return isinstance(exception, error_types)


async def _calculate_retry_delay(attempt: int) -> float:
  """è®¡ç®—é‡è¯•å»¶è¿Ÿæ—¶é—´ï¼Œä½¿ç”¨æŒ‡æ•°é€€é¿å’ŒæŠ–åŠ¨"""
  base_delay = min(
    INITIAL_RETRY_DELAY * (RETRY_BACKOFF_FACTOR ** attempt),
    MAX_RETRY_DELAY
  )

  # æ·»åŠ éšæœºæŠ–åŠ¨ï¼Œé¿å…æ‰€æœ‰é‡è¯•åŒæ—¶å‘ç”Ÿ
  jitter = random.uniform(0.1, 0.3) * base_delay
  delay = base_delay + jitter

  logger.debug(f"Retry attempt {attempt + 1}, delay: {delay:.2f}s")
  return delay


def _get_api_key_from_request(request: Request) -> Optional[str]:
  # ä¼˜å…ˆä»headerè·å–
  api_key = request.headers.get("x-goog-api-key")
  if api_key:
    logger.debug("API key found in x-goog-api-key header")
    return api_key

  # ä»æŸ¥è¯¢å‚æ•°è·å–
  api_key = request.query_params.get("key")
  if api_key:
    logger.debug("API key found in query parameters")
    return api_key

  logger.warning("API key not found in headers or query parameters")
  return None


async def _execute_proxy_request_with_retry(
  request: Request,
  db: db_dependency,
  full_target_url: str,
  stream: bool,
  query_params_to_send: Dict[str, Any],
  max_retries: int = 3
) -> Any:
  """æ‰§è¡Œå¸¦é‡è¯•çš„ä»£ç†è¯·æ±‚ï¼Œæ¯æ¬¡é‡è¯•ä½¿ç”¨æ–°çš„APIå¯†é’¥"""
  last_exception = None
  # æ€»å°è¯•æ¬¡æ•° = 1æ¬¡åŸå§‹è¯·æ±‚ + max_retriesæ¬¡é‡è¯•
  total_attempts = max_retries + 1

  # Log retry configuration at start
  logger.info(f"Starting proxy request execution, max retries: {max_retries}, total attempts: {total_attempts}")

  for attempt in range(total_attempts):
    try:
      # Determine if this is a retry
      if attempt == 0:
        logger.info(f"Executing initial request (attempt {attempt + 1}/{total_attempts})")
      else:
        logger.info(f"Executing retry request (retry {attempt}/{max_retries}, total attempt {attempt + 1}/{total_attempts})")

      logger.debug(f"Proxy request attempt {attempt + 1}/{total_attempts}")

      # æ¯æ¬¡å°è¯•éƒ½è·å–æ–°çš„APIå¯†é’¥
      current_api_key_obj = KeyManager.get_active_api_key(db)
      if current_api_key_obj:
        logger.debug(f"Using API key for attempt {attempt + 1}: {current_api_key_obj.key_name if hasattr(current_api_key_obj, 'key_name') else 'unnamed'}")

      response = await base_proxy_request(
        request=request,
        db=db,
        full_target_url=full_target_url,
        stream=stream,
        skip_token_validation=True,
        params=query_params_to_send,
        api_key_header_name="x-goog-api-key",
        selected_key_obj=current_api_key_obj,
      )

      # è¯·æ±‚æˆåŠŸï¼Œè¿”å›å“åº”
      if attempt == 0:
        logger.info(f"âœ… Proxy request succeeded (initial request successful, no retries needed)")
      else:
        logger.info(f"âœ… Proxy request retry succeeded (succeeded after {attempt} retries, total {attempt + 1} attempts)")

      return response

    except Exception as e:
      last_exception = e

      # Determine if this is a retry failure
      if attempt == 0:
        logger.warning(f"âŒ Initial request failed (attempt {attempt + 1}/{total_attempts}): {str(e)}")
      else:
        logger.warning(f"âŒ Retry request failed (retry {attempt}/{max_retries}, total attempt {attempt + 1}/{total_attempts}): {str(e)}")

      # åˆ¤æ–­æ˜¯å¦å¯ä»¥é‡è¯•
      if not _is_retryable_error(e):
        logger.info(f"ğŸš« Error is not retryable, throwing exception directly: {type(e).__name__}")
        raise e

      # å¦‚æœè¿™æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œä¸å†é‡è¯•
      if attempt == total_attempts - 1:
        logger.error(f"ğŸ’¥ All attempts failed (initial request + {max_retries} retries = {total_attempts} total attempts all failed)")
        break

      # è®¡ç®—å»¶è¿Ÿæ—¶é—´å¹¶ç­‰å¾…
      delay = await _calculate_retry_delay(attempt)
      logger.info(f"â³ Preparing retry {attempt + 1}/{max_retries}, will retry with new API key after {delay:.2f} seconds...")
      await asyncio.sleep(delay)

  # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºæœ€åä¸€ä¸ªå¼‚å¸¸
  logger.error(f"ğŸ”¥ Retry mechanism completed, all {total_attempts} attempts failed, throwing last exception")
  if last_exception:
    raise last_exception


@router.api_route(
  "/{path:path}", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS", "HEAD"]
)
async def gemini_pure_proxy_request(path: str, request: Request, db: db_dependency):
  """
  Geminiçº¯ä»£ç†è¯·æ±‚å¤„ç†

  ä¼˜åŒ–è¦ç‚¹ï¼š
  1. é…ç½®ç¼“å­˜å‡å°‘æ•°æ®åº“æŸ¥è¯¢
  2. ç»Ÿä¸€çš„é”™è¯¯å¤„ç†
  3. è¯·æ±‚ä½“ä¸€æ¬¡æ€§è¯»å–é¿å…é‡å¤
  4. æ›´å¥å£®çš„å‚æ•°è§£æ
  """
  # 1. éªŒè¯è¯·æ±‚è·¯å¾„
  if not request.url.path.startswith(settings.GEMINI_PURE_PROXY_PREFIX):
    logger.warning(f"Invalid request path: {request.url.path}")
    raise HTTPException(status_code=404, detail="Not Found")

  logger.info(f"Processing Gemini proxy request: path='{path}', method='{request.method}'")

  try:
    # 2. è·å–ç¼“å­˜çš„é…ç½®
    target_api_url, api_token, retry_count = _get_cached_configs(db)

    if not target_api_url:
      raise HTTPException(status_code=503, detail="ç›®æ ‡ Gemini API URL æœªé…ç½®ï¼Œè¯·åœ¨é…ç½®è¡¨ä¸­æ·»åŠ  'target_api_url'ã€‚")
    if not api_token:
      raise HTTPException(status_code=503, detail="å†…éƒ¨ API ä»¤ç‰Œæœªé…ç½®ã€‚")

    # 3. æ„å»ºç›®æ ‡URL
    target_url = target_api_url.rstrip("/")
    full_target_url = f"{target_url}/{path}"
    logger.debug(f"Target URL: {full_target_url}")

    # 4. ç¡®å®šæ˜¯å¦ä¸ºæµå¼è¯·æ±‚
    stream = False
    cached_body = None

    # æ£€æŸ¥æŸ¥è¯¢å‚æ•°ä¸­çš„alt=sse
    if request.query_params.get("alt") == "sse":
      stream = True
      logger.debug("Streaming enabled via 'alt=sse' query parameter")
    else:
      # è¯»å–è¯·æ±‚ä½“ä¸€æ¬¡ï¼Œé¿å…é‡å¤è¯»å–
      body = await request.body()
      if body:
        stream, cached_body = _extract_stream_parameter(body)

    # 5. éªŒè¯å†…éƒ¨APIå¯†é’¥
    internal_api_key = _get_api_key_from_request(request)

    if not internal_api_key or internal_api_key != api_token:
      logger.warning("Invalid or missing internal API key")
      raise HTTPException(
        status_code=401,
        detail="Invalid or missing internal API key."
      )

    # 6. å‡†å¤‡æŸ¥è¯¢å‚æ•°ï¼ˆç§»é™¤å†…éƒ¨keyï¼‰
    query_params_to_send = dict(request.query_params)
    query_params_to_send.pop("key", None)

    # 7. è°ƒç”¨å¸¦é‡è¯•çš„åŸºç¡€ä»£ç†ï¼Œä½¿ç”¨ç¼“å­˜çš„é‡è¯•æ¬¡æ•°
    # APIå¯†é’¥å°†åœ¨é‡è¯•å‡½æ•°å†…éƒ¨åŠ¨æ€è·å–
    response = await _execute_proxy_request_with_retry(
      request=request,
      db=db,
      full_target_url=full_target_url,
      stream=stream,
      query_params_to_send=query_params_to_send,
      max_retries=retry_count
    )

    return response

  except ProxyError as pe:
    # å¤„ç†ProxyErrorï¼Œè½¬æ¢ä¸ºHTTPException
    raise HTTPException(status_code=pe.status_code, detail=pe.detail)
  except HTTPException:
    # é‡æ–°æŠ›å‡ºHTTPå¼‚å¸¸ï¼Œä¿æŒåŸæœ‰çŠ¶æ€ç 
    raise
  except Exception as e:
    logger.error(f"Unexpected error in gemini_pure_proxy_request: {e}", exc_info=True)
    raise HTTPException(
      status_code=500,
      detail="Internal server error occurred while processing the request."
    )

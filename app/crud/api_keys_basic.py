import logging
from typing import List
from sqlalchemy import select, insert
from sqlalchemy.orm import Session

from ..models import models
from ..schemas import schemas

logger = logging.getLogger(__name__)


def get_api_key(db: Session, api_key_id: int):
    """
    æ ¹æ® ID è·å–å•ä¸ª API Keyã€‚
    """
    return db.query(models.ApiKey).filter(models.ApiKey.id == api_key_id).first()


def get_api_key_by_value(db: Session, key_value: str):
    """
    æ ¹æ® Key å€¼è·å–å•ä¸ª API Keyã€‚
    """
    return db.query(models.ApiKey).filter(models.ApiKey.key_value == key_value).first()


def get_api_keys(db: Session, skip: int = 0, limit: int = 100):
    """
    è·å– API Key åˆ—è¡¨ã€‚
    """
    return db.query(models.ApiKey).offset(skip).limit(limit).all()


def create_api_key(db: Session, api_key: schemas.ApiKeyCreate):
    """
    åˆ›å»ºä¸€ä¸ªæ–°çš„ API Keyã€‚å¦‚æœ Key å­˜åœ¨åˆ™ä¸åšå¤„ç†ï¼Œè¿”å› Noneã€‚
    """
    logger.info(f"Attempting to create single API key: {api_key.key_value}.")

    # ï¼ï¼ï¼å…ˆæŸ¥è¯¢ Key æ˜¯å¦å·²å­˜åœ¨ï¼ï¼ï¼
    existing_key = get_api_key_by_value(db, api_key.key_value)
    if existing_key:
        logger.warning(
            f"API Key '{api_key.key_value}' already exists, skipping creation."
        )
        return None

    db_api_key = models.ApiKey(**api_key.model_dump())
    db.add(db_api_key)
    logger.info(f"API Key '{api_key.key_value}' added to session.")
    return db_api_key


def update_api_key(db: Session, api_key_id: int, api_key_update: schemas.ApiKeyUpdate):
    """
    æ›´æ–° API Key ä¿¡æ¯ã€‚
    """
    from .api_keys_cache import invalidate_active_api_keys_cache
    
    db_api_key = get_api_key(db, api_key_id)
    if db_api_key:
        # æ£€æŸ¥æ˜¯å¦æ›´æ–°äº†çŠ¶æ€å­—æ®µ
        update_data = api_key_update.model_dump(exclude_unset=True)
        status_changed = 'status' in update_data and update_data['status'] != db_api_key.status
        
        for key, value in update_data.items():
            setattr(db_api_key, key, value)
        db.add(db_api_key)
        db.commit()
        db.refresh(db_api_key)
        
        # å¦‚æœçŠ¶æ€å‘ç”Ÿå˜åŒ–ï¼Œä½¿ç¼“å­˜å¤±æ•ˆ
        if status_changed:
            logger.info(f"ğŸ”„ [CACHE] API key {api_key_id} status changed, invalidating cache")
            invalidate_active_api_keys_cache()
            
    return db_api_key


def delete_api_key(db: Session, api_key_id: int):
    """
    åˆ é™¤ API Keyã€‚
    """
    from .api_keys_cache import invalidate_active_api_keys_cache
    
    db_api_key = get_api_key(db, api_key_id)
    if db_api_key:
        db.delete(db_api_key)
        db.commit()
        # åˆ é™¤API keyåä½¿ç¼“å­˜å¤±æ•ˆ
        logger.info(f"ğŸ—‘ï¸ [CACHE] API key {api_key_id} deleted, invalidating cache")
        invalidate_active_api_keys_cache()
    return db_api_key


def bulk_delete_api_keys(db: Session, api_key_ids: List[int]) -> int:
    """
    æ‰¹é‡åˆ é™¤ API Keyã€‚
    è¿”å›åˆ é™¤çš„ Key æ•°é‡ã€‚
    """
    from .api_keys_cache import invalidate_active_api_keys_cache
    
    if not api_key_ids:
        return 0

    # ä½¿ç”¨ in æ“ä½œç¬¦åˆ é™¤æŒ‡å®š ID çš„è®°å½•
    delete_count = (
        db.query(models.ApiKey)
        .filter(models.ApiKey.id.in_(api_key_ids))
        .delete(synchronize_session=False)
    )
    db.commit()
    logger.info(f"Bulk deleted {delete_count} API keys with IDs: {api_key_ids}")
    
    # æ‰¹é‡åˆ é™¤åä½¿ç¼“å­˜å¤±æ•ˆ
    if delete_count > 0:
        logger.info(f"ğŸ—‘ï¸ [CACHE] Bulk deleted {delete_count} API keys, invalidating cache")
        invalidate_active_api_keys_cache()
    
    return delete_count


def bulk_add_api_keys(db: Session, key_values: List[str]) -> int:
    """
    æ‰¹é‡æ·»åŠ  API Keyã€‚å¦‚æœ Key å­˜åœ¨åˆ™è·³è¿‡ï¼Œä¸å­˜åœ¨åˆ™æ’å…¥ã€‚
    è¿”å›æ–°æ’å…¥çš„ Key æ•°é‡ã€‚
    """
    from .api_keys_cache import invalidate_active_api_keys_cache
    
    logger.info(f"Attempting to bulk add {len(key_values)} API keys.")

    if not key_values:
        logger.info("No key values provided for bulk add.")
        return 0

    existing_keys_query = db.execute(select(models.ApiKey.key_value)).scalars().all()
    existing_keys = set(existing_keys_query)

    keys_to_add = []
    for key_value in key_values:
        cleaned_key = key_value.strip()
        if cleaned_key and cleaned_key not in existing_keys:
            keys_to_add.append(cleaned_key)
            existing_keys.add(cleaned_key)

    if not keys_to_add:
        logger.info("All provided keys already exist or are empty after cleaning.")
        return 0

    insert_data = [{"key_value": key, "status": "active"} for key in keys_to_add]

    db.execute(insert(models.ApiKey), insert_data)

    logger.info(f"Bulk added {len(keys_to_add)} new API keys.")
    
    # æ‰¹é‡æ·»åŠ åä½¿ç¼“å­˜å¤±æ•ˆ
    if len(keys_to_add) > 0:
        logger.info(f"â• [CACHE] Bulk added {len(keys_to_add)} API keys, invalidating cache")
        invalidate_active_api_keys_cache()
    
    return len(keys_to_add)


def delete_api_call_logs_by_api_key_ids(db: Session, api_key_ids: List[int]) -> int:
    """
    æ ¹æ® API Key ID æ‰¹é‡åˆ é™¤ API è°ƒç”¨æ—¥å¿—ã€‚
    è¿”å›åˆ é™¤çš„æ—¥å¿—æ•°é‡ã€‚
    """
    if not api_key_ids:
        return 0

    delete_count = (
        db.query(models.ApiCallLog)
        .filter(models.ApiCallLog.api_key_id.in_(api_key_ids))
        .delete(synchronize_session=False)
    )
    db.commit()
    logger.info(f"Bulk deleted {delete_count} API call logs for API Key IDs: {api_key_ids}")
    return delete_count
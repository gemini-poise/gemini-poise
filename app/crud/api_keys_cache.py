import logging
import json
import time
from typing import Optional, List
import redis

from ..core.config import settings

logger = logging.getLogger(__name__)

# Rediså®¢æˆ·ç«¯ç”¨äºç¼“å­˜æ´»è·ƒAPI keys
_redis_client = None

# ç¼“å­˜é…ç½®
ACTIVE_KEYS_CACHE_KEY = "active_api_keys_cache"
ACTIVE_KEYS_CACHE_TTL = 300  # 5åˆ†é’Ÿç¼“å­˜
ACTIVE_KEYS_LAST_UPDATE_KEY = "active_api_keys_last_update"

# ç¼“å­˜ç»Ÿè®¡é…ç½®
CACHE_STATS_KEY = "api_keys_cache_stats"
CACHE_STATS_TTL = 86400 * 7  # 7å¤©ç»Ÿè®¡æ•°æ®
CACHE_STATS_RESET_KEY = "api_keys_cache_stats_reset"


def get_redis_client():
    """è·å–Rediså®¢æˆ·ç«¯å®ä¾‹"""
    global _redis_client
    if _redis_client is None:
        _redis_client = redis.from_url(
            settings.REDIS_URL,
            password=settings.REDIS_PASSWORD,
            decode_responses=True
        )
    return _redis_client


def get_cached_active_api_key_ids(record_stats: bool = True) -> Optional[List[int]]:
    """
    ä»Redisç¼“å­˜è·å–æ´»è·ƒAPI key IDsåˆ—è¡¨
    
    Args:
        record_stats: æ˜¯å¦è®°å½•ç¼“å­˜ç»Ÿè®¡ï¼Œé»˜è®¤ä¸ºTrue
    
    Returns:
        Optional[List[int]]: æ´»è·ƒAPI key IDsåˆ—è¡¨ï¼Œå¦‚æœç¼“å­˜ä¸å­˜åœ¨æˆ–è¿‡æœŸåˆ™è¿”å›None
    """
    try:
        redis_client = get_redis_client()
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
        cached_data = redis_client.get(ACTIVE_KEYS_CACHE_KEY)
        if not cached_data:
            logger.debug("No cached active API keys found")
            if record_stats:
                record_cache_access(hit=False)
            return None
        
        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
        last_update = redis_client.get(ACTIVE_KEYS_LAST_UPDATE_KEY)
        if last_update:
            last_update_time = float(last_update)
            if time.time() - last_update_time > ACTIVE_KEYS_CACHE_TTL:
                logger.debug("Cached active API keys expired")
                if record_stats:
                    record_cache_access(hit=False)
                return None
        
        # è§£æç¼“å­˜æ•°æ®
        key_ids = json.loads(cached_data)
        logger.debug(f"ğŸ¯ [CACHE] Retrieved {len(key_ids)} active API key IDs from cache")
        if record_stats:
            record_cache_access(hit=True)
        return key_ids
        
    except Exception as e:
        logger.warning(f"âš ï¸ [CACHE] Failed to get cached active API keys: {e}")
        if record_stats:
            record_cache_access(hit=False)
        return None


def cache_active_api_key_ids(key_ids: List[int]):
    """
    å°†æ´»è·ƒAPI key IDsåˆ—è¡¨ç¼“å­˜åˆ°Redis
    
    Args:
        key_ids: æ´»è·ƒAPI key IDsåˆ—è¡¨
    """
    try:
        redis_client = get_redis_client()
        
        # ç¼“å­˜æ•°æ®
        cached_data = json.dumps(key_ids)
        redis_client.setex(ACTIVE_KEYS_CACHE_KEY, ACTIVE_KEYS_CACHE_TTL * 2, cached_data)  # è®¾ç½®æ›´é•¿çš„TTLé˜²æ­¢æ„å¤–è¿‡æœŸ
        
        # è®°å½•æ›´æ–°æ—¶é—´
        redis_client.setex(ACTIVE_KEYS_LAST_UPDATE_KEY, ACTIVE_KEYS_CACHE_TTL * 2, str(time.time()))
        
        logger.info(f"ğŸ’¾ [CACHE] Cached {len(key_ids)} active API key IDs to Redis")
        
    except Exception as e:
        logger.error(f"âŒ [CACHE] Failed to cache active API keys: {e}")


def invalidate_active_api_keys_cache():
    """
    ä½¿æ´»è·ƒAPI keysç¼“å­˜å¤±æ•ˆ
    """
    try:
        redis_client = get_redis_client()
        redis_client.delete(ACTIVE_KEYS_CACHE_KEY, ACTIVE_KEYS_LAST_UPDATE_KEY)
        logger.info("ğŸ—‘ï¸ [CACHE] Invalidated active API keys cache")
    except Exception as e:
        logger.error(f"âŒ [CACHE] Failed to invalidate active API keys cache: {e}")


def record_cache_access(hit: bool):
    """
    è®°å½•ç¼“å­˜è®¿é—®ç»Ÿè®¡
    
    Args:
        hit: æ˜¯å¦å‘½ä¸­ç¼“å­˜
    """
    try:
        redis_client = get_redis_client()
        
        # ä½¿ç”¨ Redis pipeline å’ŒåŸå­æ“ä½œæ¥æ›´æ–°ç»Ÿè®¡
        with redis_client.pipeline() as pipe:
            while True:
                try:
                    # ç›‘è§†é”®ä»¥ç¡®ä¿åŸå­æ€§
                    pipe.watch(CACHE_STATS_KEY)
                    
                    # è·å–å½“å‰ç»Ÿè®¡æ•°æ®
                    stats_data = pipe.get(CACHE_STATS_KEY)
                    if stats_data:
                        stats = json.loads(stats_data)
                    else:
                        stats = {
                            "total_requests": 0,
                            "cache_hits": 0,
                            "cache_misses": 0,
                            "start_time": time.time(),
                            "last_reset_time": None
                        }
                    
                    # æ›´æ–°ç»Ÿè®¡
                    stats["total_requests"] += 1
                    if hit:
                        stats["cache_hits"] += 1
                    else:
                        stats["cache_misses"] += 1
                    
                    # å¼€å§‹äº‹åŠ¡
                    pipe.multi()
                    pipe.setex(CACHE_STATS_KEY, CACHE_STATS_TTL, json.dumps(stats))
                    pipe.execute()
                    break
                    
                except redis.WatchError:
                    # å¦‚æœé”®è¢«å…¶ä»–å®¢æˆ·ç«¯ä¿®æ”¹ï¼Œé‡è¯•
                    continue
        
    except Exception as e:
        logger.warning(f"âš ï¸ [CACHE] Failed to record cache access: {e}")


def get_cache_statistics():
    """
    è·å–ç¼“å­˜ç»Ÿè®¡æ•°æ®
    
    Returns:
        dict: åŒ…å«ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    try:
        redis_client = get_redis_client()
        
        stats_data = redis_client.get(CACHE_STATS_KEY)
        if not stats_data:
            return {
                "total_requests": 0,
                "cache_hits": 0,
                "cache_misses": 0,
                "hit_rate": 0.0,
                "start_time": None,
                "last_reset_time": None,
                "duration_hours": 0.0
            }
        
        stats = json.loads(stats_data)
        
        # è®¡ç®—å‘½ä¸­ç‡
        total = stats.get("total_requests", 0)
        hits = stats.get("cache_hits", 0)
        hit_rate = (hits / total * 100) if total > 0 else 0.0
        
        # è®¡ç®—è¿è¡Œæ—¶é•¿
        start_time = stats.get("start_time", time.time())
        duration_hours = (time.time() - start_time) / 3600
        
        return {
            "total_requests": total,
            "cache_hits": hits,
            "cache_misses": stats.get("cache_misses", 0),
            "hit_rate": round(hit_rate, 2),
            "start_time": start_time,
            "last_reset_time": stats.get("last_reset_time"),
            "duration_hours": round(duration_hours, 2)
        }
        
    except Exception as e:
        logger.error(f"âŒ [CACHE] Failed to get cache statistics: {e}")
        return {
            "total_requests": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "hit_rate": 0.0,
            "start_time": None,
            "last_reset_time": None,
            "duration_hours": 0.0
        }


def reset_cache_statistics():
    """
    é‡ç½®ç¼“å­˜ç»Ÿè®¡æ•°æ®
    """
    try:
        redis_client = get_redis_client()
        
        reset_stats = {
            "total_requests": 0,
            "cache_hits": 0,
            "cache_misses": 0,
            "start_time": time.time(),
            "last_reset_time": time.time()
        }
        
        redis_client.setex(CACHE_STATS_KEY, CACHE_STATS_TTL, json.dumps(reset_stats))
        logger.info("ğŸ”„ [CACHE] Reset cache statistics")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ [CACHE] Failed to reset cache statistics: {e}")
        return False